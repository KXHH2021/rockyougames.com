---
title: Kernel Memory 入门系列:文档预处理
date: 2023-12-19 20:00:00
categories:
  - Kernel Memory
tags:
  - Embedding
  - markdown
description: Kernel Memory 入门系列:文档预处理
cover: https://s2.loli.net/2024/01/07/V7cozqQDv8sMUC6.png
---
## Kernel Memory 入门系列：文档预处理
Embedding为我们提供了问题理解和文档检索的方法，但是面对大量的文档，如果在用于提问的时候再进行文档的Embedding的话，那这个过程是非常耗时的，再加之我们的文档并不会频繁变化，所以我们可以对文档进行预处理，提升检索的效率。

![image.png](https://s2.loli.net/2024/01/07/V7cozqQDv8sMUC6.png)

## 文档的预处理大致分为了几个步骤：

- 1.文档的准备

首先需要把我们已有的文档整理出来，起码是需要进行检索的这些文档。文档的格式不会有很大的限制，可以是docx，也可以是pdf或者ppt，当然也可以是txt或者markdown，哪怕是图片、网页或者其他可以提取文本的文档格式都可以。

- 2.文本的提取

文本提取的过程，就是将已经整理好的文档中的文字提取出来，根据不同的文档类型匹配相应的提取方法。Kernel Memory中已经默认集成了docx、excel、ppt、pdf、plaintext(markdown、text)、json、image(via OCR)等类型的文本提取方法，如果有其他的文档类型，也可以自行添加。

- 3.文本的分片

我们的文档往往比较大，如果直接进行检索使用的话，会导致最终的提示词上下文太长，从而造成Token的浪费。另外提示词太长的话，生成的速度也会变慢，从而费时费钱。

其实另外一个最主要的原因是embedding的接口是有token限制的，所以太长的话要么造成信息丢失，要么引起生成错误。

所以最好的方法就是将文本进行分片处理。Kernel Memory中提供了一个默认的分片方法，根据文本的长度、段落、句子、标点符号等进行分片，当然也可以自行添加。

- 4.文档存储

这里其实只是做一个持久化的过程，可以用于管理文档处理的进度。

- 5.文本的Embedding

将分片好的文本进行Embedding，得到对应的向量。根据实际的需求，可以选用不同的Embedding模型，但是需要确保，最终和最终检索所使用的Embedding模型保持一致。

- 6.存储到向量数据库

将Embedding的结果存储到向量数据库中，这样的话，我们就可以在检索的时候，直接从向量数据库中读取向量，而不需要再进行Embedding，从而提升检索的效率。

**一些其他的过程：**

整个文档预处理的过程是讲已有的文本最终转化为向量，存储到向量数据库的过程。在这个处理流程中，另外需要消息队列来管理处理的进度。如果需要进行的文档的更新的话，可以使用文档删除的方法，将文档从向量数据库中删除，然后重新进行文档导入处理。
